[
    {
        "config": {
            "norm_layer": "rmsnorm",
            "attention": "GQA",
            "activation": "geglu"
        },
        "val_loss": 3.3525,
        "memory_usage": 47559,
        "step_time": null
    },
    {
        "config": {
            "norm_layer": "rmsnorm",
            "attention": "self",
            "activation": "geglu"
        },
        "val_loss": 3.3647,
        "memory_usage": 47702,
        "step_time": null
    },
    {
        "config": {
            "norm_layer": "layernorm",
            "attention": "GQA",
            "activation": "geglu"
        },
        "val_loss": 3.3768,
        "memory_usage": 47567,
        "step_time": null
    },
    {
        "config": {
            "norm_layer": "rmsnorm",
            "attention": "self",
            "activation": "gelu"
        },
        "val_loss": 3.3932,
        "memory_usage": 42541,
        "step_time": null
    },
    {
        "config": {
            "norm_layer": "layernorm",
            "attention": "self",
            "activation": "gelu"
        },
        "val_loss": 3.3947,
        "memory_usage": 42547,
        "step_time": null
    },
    {
        "config": {
            "norm_layer": "rmsnorm",
            "attention": "GQA",
            "activation": "gelu"
        },
        "val_loss": 3.4012,
        "memory_usage": 42404,
        "step_time": null
    },
    {
        "config": {
            "norm_layer": "layernorm",
            "attention": "self",
            "activation": "geglu"
        },
        "val_loss": 3.4043,
        "memory_usage": 47708,
        "step_time": null
    },
    {
        "config": {
            "norm_layer": "layernorm",
            "attention": "GQA",
            "activation": "gelu"
        },
        "val_loss": 3.4167,
        "memory_usage": 42409,
        "step_time": null
    }
]

Training with configuration: {'norm_layer': 'rmsnorm', 'attention': 'GQA', 'activation': 'geglu'
}
Results: val_loss=3.3525, memory_usage=47559MB, step_time=Nonems
--------------------------------------------------
Training with configuration: {'norm_layer': 'rmsnorm', 'attention': 'GQA', 'activation': 'gelu'
}
Results: val_loss=3.4012, memory_usage=42404MB, step_time=Nonems
--------------------------------------------------
Training with configuration: {'norm_layer': 'rmsnorm', 'attention': 'self', 'activation': 'geglu'
}
Results: val_loss=3.3647, memory_usage=47702MB, step_time=Nonems
--------------------------------------------------
Training with configuration: {'norm_layer': 'rmsnorm', 'attention': 'self', 'activation': 'gelu'
}
Results: val_loss=3.3932, memory_usage=42541MB, step_time=Nonems
--------------------------------------------------
Training with configuration: {'norm_layer': 'layernorm', 'attention': 'GQA', 'activation': 'geglu'
}
Results: val_loss=3.3768, memory_usage=47567MB, step_time=Nonems
--------------------------------------------------
Training with configuration: {'norm_layer': 'layernorm', 'attention': 'GQA', 'activation': 'gelu'
}
Results: val_loss=3.4167, memory_usage=42409MB, step_time=Nonems
--------------------------------------------------
Training with configuration: {'norm_layer': 'layernorm', 'attention': 'self', 'activation': 'geglu'
}
Results: val_loss=3.4043, memory_usage=47708MB, step_time=Nonems
--------------------------------------------------
Training with configuration: {'norm_layer': 'layernorm', 'attention': 'self', 'activation': 'gelu'
}
Results: val_loss=3.3947, memory_usage=42547MB, step_time=Nonems
--------------------------------------------------